2024-03-13 17:06:28,822 INFO    [main.py, 199] batch size: 2
2024-03-13 17:06:29,100 INFO    [offset_helper.py, 51] engery/max-distance: 5 engery/min-distance: 0
2024-03-13 17:06:29,100 INFO    [offset_helper.py, 58] direction/num_classes: 8 scale: 1
2024-03-13 17:06:29,100 INFO    [offset_helper.py, 65] c4 align axis: False
2024-03-13 17:06:30,830 INFO    [module_runner.py, 46] BN Type is torchsyncbn.
2024-03-13 17:06:30,831 INFO    [__init__.py, 17] Using evaluator: StandardEvaluator
2024-03-13 17:06:30,831 INFO    [running_score.py, 129] 19
2024-03-13 17:06:32,196 INFO    [trainer_contrastive.py, 54] Params Group Method: None
2024-03-13 17:06:32,199 INFO    [optim_scheduler.py, 92] Use lambda_poly policy with default power 0.9
2024-03-13 17:06:32,200 INFO    [data_loader.py, 128] use the DefaultLoader for train...
2024-03-13 17:06:32,264 INFO    [default_loader.py, 34] train 100
2024-03-13 17:06:32,264 INFO    [data_loader.py, 160] use DefaultLoader for val ...
2024-03-13 17:06:32,304 INFO    [default_loader.py, 34] val 100
2024-03-13 17:06:32,305 INFO    [loss_manager.py, 63] use loss: fs_auxce_loss.
2024-03-13 17:06:32,305 INFO    [trainer_contrastive.py, 82] with_contrast: False, warmup_iters: 0, with_memory: False
2024-03-13 17:06:32,953 INFO    [data_helper.py, 126] Input keys: ['img']
2024-03-13 17:06:32,953 INFO    [data_helper.py, 127] Target keys: ['labelmap']
2024-03-13 17:07:14,691 INFO    [trainer_contrastive.py, 274] Train Epoch: 0	Train Iteration: 10	Time 42.383s / 10iters, (4.238)	Forward Time 7.041s / 10iters, (0.704)	Backward Time 21.122s / 10iters, (2.112)	Loss Time 4.965s / 10iters, (0.497)	Data load 9.254s / 10iters, (0.925387)
Learning rate = [0.00999797497721687, 0.00999797497721687]	Loss = 1.51469827 (ave = 2.98169078)

2024-03-13 17:07:33,331 INFO    [trainer_contrastive.py, 274] Train Epoch: 0	Train Iteration: 20	Time 18.640s / 10iters, (1.864)	Forward Time 0.289s / 10iters, (0.029)	Backward Time 0.266s / 10iters, (0.027)	Loss Time 5.634s / 10iters, (0.563)	Data load 12.450s / 10iters, (1.244970)
Learning rate = [0.009995724898451063, 0.009995724898451063]	Loss = 1.73011839 (ave = 2.90896893)

